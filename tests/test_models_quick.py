"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ‰€æœ‰æ¨¡åž‹èƒ½å¦æ­£å¸¸å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
è¿è¡Œæ–¹å¼: python quick_test_models.py
"""
import torch
import torch.nn as nn
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
import sys
from pathlib import Path
root_dir = Path(__file__).resolve().parent.parent
if str(root_dir) not in sys.path:
    sys.path.insert(0, str(root_dir))

from btp.config import TrainConfig
from btp.model import build_model, QuantileLoss

def quick_test_all_models():
    """å¿«é€Ÿæµ‹è¯•æ‰€æœ‰æ¨¡åž‹èƒ½å¦è·‘é€š"""
    
    # æµ‹è¯•é…ç½®
    cfg = TrainConfig()
    cfg.raw_seq_len = 360
    cfg.hidden_size = 128
    cfg.dropout = 0.3
    cfg.forecast_steps = 3
    cfg.quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]
    cfg.enable_revin = True
    cfg.attn_heads = 4
    
    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    batch_size = 4
    seq_len = 360
    input_dim = 15  # å‡è®¾15ä¸ªç‰¹å¾
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print("="*60)
    
    # è¦æµ‹è¯•çš„æ¨¡åž‹åˆ—è¡¨
    models_to_test = [
        "enhanced_transformer",
        "baseline_transformer", 
        "baseline_lstm",
        "baseline_gru"
    ]
    
    results = {}
    
    for model_name in models_to_test:
        print(f"\næµ‹è¯•æ¨¡åž‹: {model_name}")
        print("-"*40)
        
        try:
            # 1. åˆ›å»ºæ¨¡åž‹
            model = build_model(cfg, input_dim, model_type=model_name)
            model = model.to(device)
            print(f"  âœ“ æ¨¡åž‹åˆ›å»ºæˆåŠŸ")
            
            # ç»Ÿè®¡å‚æ•°é‡
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            print(f"  å‚æ•°é‡: {total_params:,} (å¯è®­ç»ƒ: {trainable_params:,})")
            
            # 2. åˆ›å»ºæµ‹è¯•æ•°æ®
            x = torch.randn(batch_size, seq_len, input_dim).to(device)
            y = torch.randn(batch_size, cfg.forecast_steps).to(device)
            
            # 3. å‰å‘ä¼ æ’­
            model.train()
            output = model(x)
            expected_shape = (batch_size, cfg.forecast_steps, len(cfg.quantiles))
            
            if output.shape != expected_shape:
                raise ValueError(f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {output.shape} != {expected_shape}")
            print(f"  âœ“ å‰å‘ä¼ æ’­æˆåŠŸ, è¾“å‡ºå½¢çŠ¶: {output.shape}")
            
            # 4. è®¡ç®—æŸå¤±
            criterion = QuantileLoss(cfg).to(device)
            loss = criterion(output, y)
            print(f"  âœ“ æŸå¤±è®¡ç®—æˆåŠŸ, loss={loss.item():.6f}")
            
            # 5. åå‘ä¼ æ’­
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            print(f"  âœ“ åå‘ä¼ æ’­æˆåŠŸ")
            
            # 6. æŽ¨ç†æ¨¡å¼æµ‹è¯•
            model.eval()
            with torch.no_grad():
                output_eval = model(x)
            print(f"  âœ“ æŽ¨ç†æ¨¡å¼æˆåŠŸ")
            
            results[model_name] = "âœ“ PASS"
            print(f"\n  >>> {model_name}: å…¨éƒ¨æµ‹è¯•é€šè¿‡! <<<")
            
        except Exception as e:
            results[model_name] = f"âœ— FAIL: {str(e)}"
            print(f"\n  >>> {model_name}: æµ‹è¯•å¤±è´¥! <<<")
            print(f"  é”™è¯¯ä¿¡æ¯: {e}")
            import traceback
            traceback.print_exc()
    
    # æ±‡æ€»ç»“æžœ
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æžœæ±‡æ€»:")
    print("="*60)
    
    all_passed = True
    for model_name, result in results.items():
        status = "âœ“" if "PASS" in result else "âœ—"
        print(f"  {status} {model_name}: {result}")
        if "FAIL" in result:
            all_passed = False
    
    print("="*60)
    if all_passed:
        print("ðŸŽ‰ æ‰€æœ‰æ¨¡åž‹æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹æ­£å¼å®žéªŒã€‚")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æ¨¡åž‹æµ‹è¯•å¤±è´¥ï¼Œè¯·ä¿®å¤åŽå†è¿è¡Œæ­£å¼å®žéªŒã€‚")
        return False


if __name__ == "__main__":
    success = quick_test_all_models()
    sys.exit(0 if success else 1)
