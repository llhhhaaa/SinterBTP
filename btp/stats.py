# Copyright (c) 2026
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import pandas as pd
import numpy as np
from scipy.stats import wilcoxon
import logging

def perform_significance_test(experiment_root: str, target_model: str = "enhanced_transformer"):
    """
    è‡ªåŠ¨æ±‡æ€»æ‰€æœ‰æŠ˜(Folds)çš„æ®‹å·®å¹¶æ‰§è¡Œæ˜¾è‘—æ€§æ£€éªŒ
    """
    # --- stats.py ---

    def collect_cv_residuals(model_name):
        import glob
        # ä¿®æ­£åçš„æœç´¢è·¯å¾„ï¼šCompare_xxx/cv_results/Fold_X/Standard/diagnostics/residual_analysis.csv
        # æˆ‘ä»¬ç›´æ¥ç”¨é€šé…ç¬¦è§£å†³å±‚çº§ä¸ç¡®å®šçš„é—®é¢˜
        model_path = os.path.join(experiment_root, f"Compare_{model_name}", "cv_results")
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ Fold ä¸‹çš„æ®‹å·®æ–‡ä»¶
        search_pattern = os.path.join(model_path, "Fold_*", "**", "residual_analysis.csv")
        res_files = glob.glob(search_pattern, recursive=True)
        
        all_residuals = []
        for f in res_files:
            try:
                df = pd.read_csv(f)
                all_residuals.append(df)
                # logging.info(f"æˆåŠŸè½½å…¥æŠ˜æ•°æ®: {f}")
            except:
                continue
                
        if not all_residuals:
            return None
            
        return pd.concat(all_residuals, ignore_index=True)

    # 1. æå–ä¸»æ¨¡å‹æ•°æ®
    df_target = collect_cv_residuals(target_model)
    if df_target is None:
        print(f"âŒ æœªæ‰¾åˆ°ä¸»æ¨¡å‹ {target_model} çš„ CV æ®‹å·®æ•°æ®ã€‚")
        return
    
    target_errors = np.abs(df_target['Residual'].values)
    mae_target_all = np.mean(target_errors)

    print(f"\n" + "="*60)
    print(f"ğŸ“Š ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒæŠ¥å‘Š (åŸºäºå…¨æŠ˜æ±‡æ€», å¯¹æ¯”åŸºå‡†: {target_model})")
    print(f"ä¸»æ¨¡å‹å…¨æŠ˜å¹³å‡ MAE: {mae_target_all:.4f}")
    print("="*60)

    results = []
    # 2. è‡ªåŠ¨å¯»æ‰¾å…¶ä»– Compare_ æ–‡ä»¶å¤¹
    model_dirs = [d for d in os.listdir(experiment_root) if d.startswith("Compare_")]

    for m_dir in model_dirs:
        m_name = m_dir.replace("Compare_", "")
        if m_name == target_model: continue
        
        df_comp = collect_cv_residuals(m_name)
        if df_comp is None: continue
        
        comp_errors = np.abs(df_comp['Residual'].values)
        
        # å¯¹é½é•¿åº¦ï¼ˆé˜²æ­¢å¼‚å¸¸æƒ…å†µï¼‰
        min_len = min(len(target_errors), len(comp_errors))
        a, b = target_errors[:min_len], comp_errors[:min_len]
        
        # æ‰§è¡Œ Wilcoxon æ£€éªŒ
        stat, p_value = wilcoxon(a, b)
        mae_comp = np.mean(b)
        improvement = (mae_comp - mae_target_all) / mae_comp * 100
        sig_marker = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else "N.S."
        
        results.append({
            "Model": m_name,
            "MAE_Base": round(mae_comp, 4),
            "MAE_Proposed": round(mae_target_all, 4),
            "Improvement(%)": f"{improvement:.2f}%",
            "P-Value": f"{p_value:.4e}",
            "Significance": sig_marker
        })
        
        print(f"[Stats] {target_model} vs {m_name.upper()}:")
        print(f"   - åŸºçº¿ MAE: {mae_comp:.4f} | æå‡: {improvement:.2f}%")
        print(f"   - P-Value: {p_value:.4e} ({sig_marker})")

    # 3. ä¿å­˜æœ€ç»ˆæ±‡æ€»è¡¨
    res_df = pd.DataFrame(results)
    save_path = os.path.join(experiment_root, "statistical_comparison_report.csv")
    res_df.to_csv(save_path, index=False)
    print(f"\n[Stats] æ±‡æ€»ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {save_path}")
    return res_df
